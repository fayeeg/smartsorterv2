<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Smart Sorter - Production</title>
<style>
  body { font-family: sans-serif; text-align: center; margin: 0; padding: 0; background: #f4f4f4; }
  h2 { background: #2196f3; color: white; padding: 10px; margin: 0; font-size: 1.2em; }
  button { margin: 10px; padding: 10px 20px; font-size: 1em; border: none; border-radius: 5px; background: #4caf50; color: white; cursor: pointer; }
  button:hover { background: #45a049; }
  button.stop { background: #f44336; }
  button.stop:hover { background: #da190b; }
  button.calibrate { background: #ff9800; }
  button.calibrate:hover { background: #f57c00; }
  #webcam-container { margin-top: 10px; position: relative; }
  video { max-width: 100%; height: auto; border: 2px solid #2196f3; }
  #overlay { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); 
             background: rgba(0,0,0,0.7); color: white; padding: 20px; border-radius: 10px;
             font-size: 1.5em; display: none; }
  #label-container div { font-size: 1.2em; margin: 5px; padding: 8px; background: white; border-radius: 5px; }
  #status { margin: 10px; padding: 10px; background: #fff; border-radius: 5px; }
  .highlight { font-weight: bold; color: white; background: #2196f3 !important; }
  #debug { margin: 10px; padding: 10px; background: #fff3cd; border-radius: 5px; font-family: monospace; font-size: 0.9em; }
  .waiting { background: #ffeaa7 !important; }
  .detecting { background: #55efc4 !important; }
</style>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
</head>
<body>
<h2>Smart Trash Sorter â†’ ESP32</h2>
<div id="status">Loading model...</div>
<button id="startBtn">Start Camera & Model</button>
<button id="calibrateBtn" class="calibrate" style="display:none;">Calibrate Background</button>
<button id="bleBtn">Connect to ESP32</button>
<button id="stopBtn" class="stop">Stop & Disconnect</button>
<div id="webcam-container">
  <div id="overlay">ðŸ“· Waiting for object...</div>
</div>
<div id="label-container"></div>
<div id="debug">Debug: Waiting...</div>
<script>
window.onload = function() {
    const MODEL_URL = "./web_model/model.json";
    const CLASS_LABELS = ["cardboard", "glass", "metal", "paper", "plastic", "trash"];
    
    // Detection settings
    const CHANGE_THRESHOLD = 15;
    const CHANGE_PERCENTAGE = 15;
    const STABLE_FRAMES_REQUIRED = 5;
    const CONFIDENCE_THRESHOLD = 0.6;
    const BACKGROUND_CALIBRATION_FRAMES = 10;
    
    let model, videoElement, labelContainer;
    let bleDevice, bleCharacteristic;
    let animationId = null;
    let statusDiv = document.getElementById("status");
    let debugDiv = document.getElementById("debug");
    let overlayDiv = document.getElementById("overlay");
    let calibrateBtn = document.getElementById("calibrateBtn");
    
    let lastSentCommand = "";
    let lastSentTime = 0;
    let frameCount = 0;
    
    // Background detection
    let backgroundFrame = null;
    let calibrating = false;
    let calibrationFrames = [];
    let objectPresent = false;
    let stableFrameCount = 0;
    
    document.getElementById("startBtn").onclick = init;
    document.getElementById("calibrateBtn").onclick = calibrateBackground;
    document.getElementById("bleBtn").onclick = connectBLE;
    document.getElementById("stopBtn").onclick = stopAll;
    
    loadModel();
    
    async function loadModel() {
        try {
            statusDiv.innerHTML = "Loading model...";
            model = await tf.loadLayersModel(MODEL_URL);
            statusDiv.innerHTML = "Model loaded! Ready to start.";
            statusDiv.style.background = "#d4edda";
            console.log("Model loaded successfully");
        } catch (err) {
            statusDiv.innerHTML = "Error loading model: " + err.message;
            statusDiv.style.background = "#f8d7da";
            console.error("Model loading error:", err);
        }
    }
    
    async function init() {
        try {
            if (!model) {
                alert("Model not loaded yet. Please wait.");
                return;
            }
            
            statusDiv.innerHTML = "Starting camera...";
            
            videoElement = document.createElement("video");
            videoElement.width = 224;
            videoElement.height = 224;
            videoElement.autoplay = true;
            videoElement.playsInline = true;
            
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { 
                    facingMode: "environment",
                    width: 224,
                    height: 224
                }
            });
            
            videoElement.srcObject = stream;
            
            await new Promise((resolve) => {
                videoElement.onloadedmetadata = () => resolve();
            });
            
            document.getElementById("webcam-container").appendChild(videoElement);
            
            labelContainer = document.getElementById("label-container");
            labelContainer.innerHTML = "";
            for (let i = 0; i < CLASS_LABELS.length; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }
            
            calibrateBtn.style.display = "inline-block";
            
            await calibrateBackground();
            
            statusDiv.innerHTML = "Ready! Place object in front of camera.";
            statusDiv.style.background = "#d4edda";
            
            loop();
        } catch (err) {
            alert("Error starting camera: " + err.message);
            console.error(err);
            statusDiv.innerHTML = "Error: " + err.message;
            statusDiv.style.background = "#f8d7da";
        }
    }
    
    async function calibrateBackground() {
        if (!videoElement || calibrating) return;
        
        calibrating = true;
        calibrationFrames = [];
        statusDiv.innerHTML = "Calibrating... Keep camera still!";
        statusDiv.style.background = "#fff3cd";
        overlayDiv.style.display = "block";
        overlayDiv.innerHTML = "ðŸ“· Calibrating...<br>Keep still!";
        
        for (let i = 0; i < BACKGROUND_CALIBRATION_FRAMES; i++) {
            await new Promise(resolve => setTimeout(resolve, 100));
            
            if (videoElement.readyState === videoElement.HAVE_ENOUGH_DATA) {
                const frameTensor = tf.browser.fromPixels(videoElement)
                    .resizeNearestNeighbor([224, 224]);
                calibrationFrames.push(frameTensor);
            }
        }
        
        if (calibrationFrames.length > 0) {
            backgroundFrame = tf.stack(calibrationFrames).mean(0);
            calibrationFrames.forEach(frame => frame.dispose());
            calibrationFrames = [];
        }
        
        calibrating = false;
        statusDiv.innerHTML = "Background calibrated!";
        statusDiv.style.background = "#d4edda";
        overlayDiv.innerHTML = "ðŸ“· Waiting for object...";
        
        console.log("Background calibration complete");
    }
    
    function loop() {
        if (videoElement && videoElement.readyState === videoElement.HAVE_ENOUGH_DATA && !calibrating) {
            detectObjectAndPredict();
        }
        animationId = window.requestAnimationFrame(loop);
    }
    
    async function detectObjectAndPredict() {
        if (!backgroundFrame) return;
        
        let currentFrame = null;
        let diff = null;
        
        try {
            frameCount++;
            
            currentFrame = tf.browser.fromPixels(videoElement)
                .resizeNearestNeighbor([224, 224]);
            
            diff = tf.abs(tf.sub(currentFrame, backgroundFrame));
            const grayscaleDiff = diff.mean(2);
            const threshold = tf.scalar(CHANGE_THRESHOLD);
            const changedPixels = tf.greater(grayscaleDiff, threshold);
            
            const totalPixels = 224 * 224;
            const changedCount = (await changedPixels.sum().data())[0];
            const changePercentage = (changedCount / totalPixels) * 100;
            
            // CRITICAL: Dispose intermediate tensors
            grayscaleDiff.dispose();
            threshold.dispose();
            changedPixels.dispose();
            diff.dispose();
            
            const wasObjectPresent = objectPresent;
            objectPresent = changePercentage > CHANGE_PERCENTAGE;
            
            if (objectPresent) {
                stableFrameCount++;
                overlayDiv.style.display = "none";
                statusDiv.className = "detecting";
                
                if (stableFrameCount >= STABLE_FRAMES_REQUIRED) {
                    await predict(currentFrame);
                }
            } else {
                if (wasObjectPresent) {
                    clearPredictionDisplay();
                }
                stableFrameCount = 0;
                overlayDiv.style.display = "block";
                statusDiv.className = "waiting";
            }
            
            currentFrame.dispose();
            
            // Memory monitoring
            if (frameCount % 30 === 0) {
                const memInfo = tf.memory();
                debugDiv.innerHTML = `Frames: ${frameCount} | Tensors: ${memInfo.numTensors} | Detecting: ${objectPresent}`;
                
                // Alert if tensor count is growing (memory leak)
                if (memInfo.numTensors > 50) {
                    console.warn("High tensor count:", memInfo.numTensors);
                }
            }
            
        } catch (err) {
            console.error("Detection error:", err);
            if (currentFrame) currentFrame.dispose();
            if (diff) diff.dispose();
        }
    }
    
    async function predict(currentFrame) {
        let imageTensor = null;
        let predictionTensor = null;
        
        try {
            imageTensor = currentFrame
                .toFloat()
                .div(255.0)
                .expandDims(0);
            
            predictionTensor = model.predict(imageTensor);
            const predictions = await predictionTensor.data();
            
            // CRITICAL: Dispose tensors immediately
            imageTensor.dispose();
            predictionTensor.dispose();
            
            let maxProb = 0;
            let maxIndex = 0;
            
            for (let i = 0; i < predictions.length; i++) {
                if (isNaN(predictions[i])) {
                    console.error("NaN detected!");
                    return;
                }
                if (predictions[i] > maxProb) {
                    maxProb = predictions[i];
                    maxIndex = i;
                }
            }
            
            const bestClass = CLASS_LABELS[maxIndex];
            
            // Display predictions
            for (let i = 0; i < CLASS_LABELS.length; i++) {
                labelContainer.childNodes[i].innerHTML = 
                    `${CLASS_LABELS[i]}: ${(predictions[i] * 100).toFixed(1)}%`;
                labelContainer.childNodes[i].className = (i === maxIndex) ? "highlight" : "";
            }
            
            // Send to ESP32
            const now = Date.now();
            if (bleCharacteristic && maxProb > CONFIDENCE_THRESHOLD) {
                if (bestClass !== lastSentCommand || (now - lastSentTime) > 2000) {
                    await sendBLE(bestClass);
                    lastSentCommand = bestClass;
                    lastSentTime = now;
                }
            }
            
        } catch (err) {
            console.error("Prediction error:", err);
            if (imageTensor) imageTensor.dispose();
            if (predictionTensor) predictionTensor.dispose();
        }
    }
    
    function clearPredictionDisplay() {
        if (labelContainer) {
            for (let i = 0; i < labelContainer.childNodes.length; i++) {
                labelContainer.childNodes[i].innerHTML = `${CLASS_LABELS[i]}: -`;
                labelContainer.childNodes[i].className = "";
            }
        }
    }
    
    async function sendBLE(command) {
        try {
            let encoder = new TextEncoder();
            await bleCharacteristic.writeValue(encoder.encode(command));
            console.log(`Sent to ESP32: "${command}"`);
            statusDiv.innerHTML = `Sent "${command}" to ESP32`;
        } catch (err) {
            console.error("BLE send error:", err);
        }
    }
    
    async function connectBLE() {
        try {
            const serviceUUID = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
            const txUUID = "6e400003-b5a3-f393-e0a9-e50e24dcca9e";
            
            bleDevice = await navigator.bluetooth.requestDevice({
                filters: [{ services: [serviceUUID] }]
            });
            
            const server = await bleDevice.gatt.connect();
            const service = await server.getPrimaryService(serviceUUID);
            bleCharacteristic = await service.getCharacteristic(txUUID);
            
            statusDiv.innerHTML = "Connected to ESP32 BLE!";
            statusDiv.style.background = "#d4edda";
            alert("Connected to ESP32!");
        } catch (error) {
            console.error(error);
            alert("BLE connection failed: " + error.message);
        }
    }
    
    async function stopAll() {
        if (animationId) {
            window.cancelAnimationFrame(animationId);
            animationId = null;
        }
        
        // Clean up background frame
        if (backgroundFrame) {
            backgroundFrame.dispose();
            backgroundFrame = null;
        }
        
        // Dispose all tensors
        tf.disposeVariables();
        
        if (videoElement && videoElement.srcObject) {
            const stream = videoElement.srcObject;
            const tracks = stream.getTracks();
            tracks.forEach(track => track.stop());
            videoElement.srcObject = null;
            
            const container = document.getElementById("webcam-container");
            container.innerHTML = '<div id="overlay">ðŸ“· Waiting for object...</div>';
            overlayDiv = document.getElementById("overlay");
            videoElement = null;
        }
        
        if (bleDevice && bleDevice.gatt.connected) {
            await bleDevice.gatt.disconnect();
            bleDevice = null;
            bleCharacteristic = null;
        }
        
        if (labelContainer) {
            labelContainer.innerHTML = "";
        }
        
        calibrateBtn.style.display = "none";
        statusDiv.innerHTML = "Stopped";
        statusDiv.style.background = "#f4f4f4";
        debugDiv.innerHTML = "Debug: Stopped";
        
        frameCount = 0;
        lastSentCommand = "";
        objectPresent = false;
        
        console.log("Stopped - Memory info:", tf.memory());
    }
};
</script>
</body>
</html>
